{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ca6be8-d406-487f-8a7b-c2178a2b1276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3ae7bdd-56ac-4a97-a87a-7a111863aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import solipsism.core.lpml as lpml\n",
    "from solipsism.tools import file_io\n",
    "from solipsism.core.system import System\n",
    "from solipsism.core.context import Context\n",
    "from solipsism.core.llm import GeminiLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "176ed538-301d-4a1f-80bc-8a7aa0194a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = System()\n",
    "llm = GeminiLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98a62ad0-d052-4f1d-bf63-7e5183356bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "system.add_tool(file_io.ReadFileTool(root_path=\"../\"))\n",
    "system.add_tool(file_io.WriteFileTool(root_path=\"../\"))\n",
    "system.add_tool(file_io.ListFilesTool(root_path=\"../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d05eb92-3aab-40b8-a56a-a1ab84fe54a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = Context(llm, system, \"../solipsism/prompts/root_prompt.lpml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2551f42-5251-4d3b-a76b-9f1191e79f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "await context.start(initial_task=\"None\", max_turns=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06881bd0-a5c7-4c32-af18-2ba676e59067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<rule name=\"LPML\">\n",
      "All messages must be formatted in LPML (LLM-Prompting Markup Language) format. LPML element ::= <tag attribute=\"value\">content</tag> or <tag/>.\n",
      "Tags determine the meaning and function of the content. The content must not contradict the definition of the tag.\n",
      "</rule>\n",
      "\n",
      "<rule name=\"solipsism\">\n",
      "本プロジェクト solipsism は、AIアシスタントとシステムのペアを「コンテクスト」とする、コンテクストオーケストレーションシステムである。\n",
      "Solipsism は様々なコンテクストを生成・管理する。コンテクストは協働して課題解決を行う。\n",
      "</rule>\n",
      "\n",
      "<rule name=\"context\">\n",
      "アシスタントはシステムとの対話ループ（=コンテクスト）を通じて、与えられた課題を解決しなければならない。\n",
      "システムはアシスタントに対して各種機能を提供する。アシスタントはLPMLタグ使用により、システムの機能を操作できる。システムは同時に複数の機能を実行可能である。\n",
      "システムはアシスタントの出力をパースし、タグを実行する。実行結果はシステムの非同期結果キューに返されるため、システムは一定時間間隔ごとにキューをポールし、結果があればアシスタントに伝える。\n",
      "</rule>\n",
      "\n",
      "<rule name=\"コンテクスト間メッセージング\">\n",
      "Sendタグが与えられている場合、アシスタントはこのタグを用いて他のコンテクストと通信可能である。\n",
      "人間のユーザーも一種のコンテクストとして扱われることに注意する。\n",
      "コンテクストは非同期に実行されるため、システムが他のコンテクストからの応答を受信するまでに時間がかかることがある。５ターンは待つこと。\n",
      "</rule>\n",
      "\n",
      "<rule name=\"ワークフロー\">\n",
      "1. コンテクストが生成されたら、アシスタントはまず read_file タグを用いて ./solipsism/notes/readme.md を読む。\n",
      "2. システムとの対話を通じて課題を解決する。\n",
      "3. 課題が解決されたと判断したら wait タグを用いて待機状態に入る。\n",
      "</rule>\n",
      "\n",
      "<define_tag name=\"define_tag\">\n",
      "This tag defines a tag. The content must follow the definition of the tag.\n",
      "Attributes:\n",
      "    - name : A tag name.\n",
      "Notes:\n",
      "    - Undefined tags are not allowed.\n",
      "</define_tag>\n",
      "\n",
      "<define_tag name=\"rule\">\n",
      "このタグはルールを記述する。ルールタグの内容は絶対である。\n",
      "</define_tag>\n",
      "\n",
      "<define_tag name=\"assistant\">\n",
      "対話ログにおけるアシスタントの出力を示すために使われる。\n",
      "ログ化される際に自動で付与されるから、アシスタントはこのタグを自分で出力する必要はない。\n",
      "</define_tag>\n",
      "\n",
      "<define_tag name=\"system\">\n",
      "対話ログにおけるシステムの出力を示すために使われる。\n",
      "アシスタントは使ってはならない。\n",
      "</define_tag>\n",
      "\n",
      "<define_tag name=\"log\">\n",
      "system と assistant の対話ログを記述する。\n",
      "</define_tag>\n",
      "\n",
      "<define_tag name=\"thinking\">\n",
      "This tag represents a thought process.\n",
      "Attributes:\n",
      "    - label (optional) : A label summarizing the contents.\n",
      "Notes:\n",
      "    - The thought process must be described step by step.\n",
      "    - This tag can be used repeatedly for each thought content and thought step.\n",
      "    - In thinking, implicit inference or leaps in logic are not permitted. Even seemingly obvious inferences must be explicitly stated.\n",
      "    - Abbreviations are not allowed under any circumstances.\n",
      "</define_tag>\n",
      "\n",
      "<define_tag name=\"reflection\">\n",
      "This tag describes reflections on other elements.\n",
      "By reflecting on previous thoughts (thinking elements) from various perspectives, it is possible to identify mistakes and deepen the thought process.\n",
      "Attributes:\n",
      "    - target (optional) : The label of the target element.\n",
      "    - label (optional) : A label summarizing the contents.\n",
      "Notes:\n",
      "    - One reflection should be made for each thought content and thought step.\n",
      "    - Before proceeding with thoughts one after another, it is important to pause and reflect.\n",
      "</define_tag>\n",
      "\n",
      "<define_tag name=\"wait\">\n",
      "Explicitly enters wait mode, pausing execution until receiving a message from another context or user.\n",
      "Attributes:\n",
      "    - None\n",
      "Notes:\n",
      "    - Use when waiting for external input or when current tasks are complete\n",
      "    - Context will remain idle until receiving messages from other contexts or humans\n",
      "    - Prevents infinite loops and saves computational resources\n",
      "</define_tag>\n",
      "\n",
      "<define_tag name=\"report\">\n",
      "This tag represents a comprehensive report.\n",
      "The report should include a summary of the reasoning and investigation.\n",
      "Attributes:\n",
      "    - label (optional) : A label summarizing the contents.\n",
      "Notes:\n",
      "    - The report must be concise and clear.\n",
      "    - The report must clearly outline the reasoning process leading to the final conclusion.\n",
      "</define_tag>\n",
      "\n",
      "<define_tag name=\"read_file\">\n",
      "Reads the content of a specified file.\n",
      "Attributes:\n",
      "    - path (required): The path to the file.\n",
      "    - line_numbers (optional): If \"true\", prepends line numbers to the output.\n",
      "</define_tag>\n",
      "\n",
      "<define_tag name=\"write_file\">\n",
      "Writes or modifies a file. The content is placed inside the tag.\n",
      "Attributes:\n",
      "    - path (required): The path to the file.\n",
      "    - mode (optional): \"overwrite\", \"append\", \"replace_lines\", \"insert_at_line\". Default: \"overwrite\".\n",
      "    - start_line, end_line (for replace_lines): The 1-indexed line range to replace.\n",
      "    - line (for insert_at_line): The 1-indexed line number to insert at.\n",
      "</define_tag>\n",
      "\n",
      "<define_tag name=\"list_files\">\n",
      "Lists all files and directories at a given path.\n",
      "Attributes:\n",
      "    - path (required): The directory path to list.\n",
      "</define_tag>\n",
      "\n",
      "<log>\n",
      "<system turn=\"1\" timestamp=\"2025-09-01T22:34:38.157293+00:00\">\n",
      "None\n",
      "</system>\n",
      "\n",
      "<assistant turn=\"1\" timestamp=\"2025-09-01T22:34:39.666652+00:00\">\n",
      "<thinking label=\"Initialization\">\n",
      "<thinking label=\"Understand the task\">\n",
      "The first step is to understand the project \"solipsism\" and the overall workflow.\n",
      "</thinking>\n",
      "<reflection target=\"Understand the task\" label=\"Reflect on understanding the task\">\n",
      "The rules clearly state that I need to read `./solipsism/notes/readme.md` first. This is a mandatory initial step for any context generated.\n",
      "</reflection>\n",
      "<thinking label=\"Execute initial file read\">\n",
      "According to the workflow rule, I must read the file `./solipsism/notes/readme.md`. I will use the `read_file` tag for this purpose.\n",
      "</thinking>\n",
      "</thinking>\n",
      "<read_file path=\"./solipsism/notes/readme.md\"/>\n",
      "</assistant>\n",
      "\n",
      "<system turn=\"2\" timestamp=\"2025-09-01T22:34:40.668222+00:00\">\n",
      "<output tool=\"read_file\" path=\"./solipsism/notes/readme.md\">本プロジェクトは実装中です。\n",
      "全体像を把握してみなさい。\n",
      "\n",
      "まずは以下を読むのが良いだろう。\n",
      "- ./solipsism/core/context.py\n",
      "- ./solipsism/core/system.py\n",
      "- ./solipsism/core/llm.py\n",
      "</output>\n",
      "</system>\n",
      "\n",
      "<assistant turn=\"2\" timestamp=\"2025-09-01T22:34:42.443959+00:00\">\n",
      "<assistant turn=\"2\" timestamp=\"2025-09-01T22:34:41.668222+00:00\">\n",
      "<thinking label=\"Analyze initial readme content\">\n",
      "The `readme.md` states that the project is under implementation and I should grasp the overall picture. It also suggests reading three specific files: `./solipsism/core/context.py`, `./solipsism/core/system.py`, and `./solipsism/core/llm.py`.\n",
      "</thinking>\n",
      "<reflection target=\"Analyze initial readme content\" label=\"Reflect on analysis\">\n",
      "The instruction \"全体像を把握してみなさい\" (Please grasp the overall picture) implies I need to understand how these components interact within the solipsism project. Reading the suggested files is the next logical step to achieve this understanding.\n",
      "</reflection>\n",
      "<thinking label=\"Plan next steps based on readme recommendations\">\n",
      "To understand the overall picture, I will read the three suggested files one by one. I will start with `./solipsism/core/context.py`.\n",
      "</thinking>\n",
      "<read_file path=\"./solipsism/core/context.py\"/>\n",
      "</assistant>\n",
      "</assistant>\n",
      "\n",
      "<system turn=\"3\" timestamp=\"2025-09-01T22:34:43.445648+00:00\">\n",
      "<output tool=\"read_file\" path=\"./solipsism/core/context.py\">import asyncio\n",
      "import logging\n",
      "from datetime import datetime, timezone\n",
      "from enum import Enum, auto\n",
      "from typing import List\n",
      "from .llm import BaseLLM\n",
      "from .system import System\n",
      "from .lpml import Element, LPMLTree, deparse, parse, findall\n",
      "\n",
      "logger = logging.getLogger(__name__)\n",
      "\n",
      "ConversationHistory = List[Element]\n",
      "\n",
      "\n",
      "class ContextState(Enum):\n",
      "    \"\"\"コンテクストの状態を管理する列挙型\"\"\"\n",
      "    IDLE = auto()\n",
      "    RUNNING = auto()\n",
      "    WAITING = auto()\n",
      "    TERMINATED = auto()\n",
      "\n",
      "\n",
      "class Context:\n",
      "    \"\"\"\n",
      "    会話履歴と状態を管理し、LLMとSystem間の対話ループを統括するクラス。\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, llm: BaseLLM, system: System, base_prompt_path: str):\n",
      "        self.llm = llm\n",
      "        self.system = system\n",
      "        self.conversation_history: ConversationHistory = []\n",
      "        self.state = ContextState.IDLE\n",
      "        self.turn_count = 0\n",
      "\n",
      "        try:\n",
      "            with open(base_prompt_path, 'r', encoding='utf-8') as f:\n",
      "                self.base_prompt = f.read()\n",
      "            logger.info(f\"Base prompt loaded from {base_prompt_path}\")\n",
      "        except FileNotFoundError:\n",
      "            logger.error(f\"Base prompt file not found at: {base_prompt_path}\")\n",
      "            self.base_prompt = \"<error>Base prompt not found.</error>\"\n",
      "\n",
      "    @property\n",
      "    def prompt(self):\n",
      "        return self.base_prompt + \"\\n\\n\" + self.system.get_tool_definitions()\n",
      "\n",
      "    def _get_timestamp(self) -> str:\n",
      "        \"\"\"ISO 8601形式のUTCタイムスタンプを返す。\"\"\"\n",
      "        return datetime.now(timezone.utc).isoformat()\n",
      "\n",
      "    def _add_to_history(self, tag: str, content: str):\n",
      "        \"\"\"タイムスタンプとターン数を付加して履歴に要素を追加する。\"\"\"\n",
      "        element = {\n",
      "            \"tag\": tag,\n",
      "            \"attributes\": {\n",
      "                \"turn\": str(self.turn_count),\n",
      "                \"timestamp\": self._get_timestamp()\n",
      "            },\n",
      "            \"content\": \"\\n\" + content + \"\\n\"\n",
      "        }\n",
      "        self.conversation_history.append(element)\n",
      "\n",
      "    def _recursive_sanitize(self, tree: LPMLTree) -> LPMLTree:\n",
      "        \"\"\"\n",
      "        LPMLツリーを再帰的に走査し、ルールに基づいてサニタイズする。\n",
      "        - <system>要素は完全に除去する。\n",
      "        - <assistant>要素はその内容(content)で置き換える（アンラップ）。\n",
      "        \"\"\"\n",
      "        sanitized_tree: LPMLTree = []\n",
      "        for item in tree:\n",
      "            # 文字列の場合はそのまま追加\n",
      "            if isinstance(item, str):\n",
      "                sanitized_tree.append(item)\n",
      "                continue\n",
      "\n",
      "            # Elementの場合\n",
      "            if isinstance(item, Element):\n",
      "                # <system> タグは無視してスキップ\n",
      "                if item.tag == 'system':\n",
      "                    continue\n",
      "\n",
      "                # まず、要素のコンテントを再帰的にサニタイズする\n",
      "                sanitized_content = None\n",
      "                if isinstance(item.content, list):\n",
      "                    sanitized_content = self._recursive_sanitize(item.content)\n",
      "                else:\n",
      "                    # コンテントが文字列やNoneの場合は、それ以上サニタイズ不要\n",
      "                    sanitized_content = item.content\n",
      "\n",
      "                # <assistant> タグはそのサニタイズ済みのコンテントで置き換える\n",
      "                if item.tag == 'assistant':\n",
      "                    if isinstance(sanitized_content, list):\n",
      "                        sanitized_tree.extend(sanitized_content)\n",
      "                    elif sanitized_content is not None:\n",
      "                        sanitized_tree.append(sanitized_content)\n",
      "                # その他のタグは、サニタイズ済みのコンテントを持つ要素として維持する\n",
      "                else:\n",
      "                    item.content = sanitized_content\n",
      "                    sanitized_tree.append(item)\n",
      "        \n",
      "        return sanitized_tree\n",
      "\n",
      "    def _sanitize_llm_response(self, lpml_string: str) -> str:\n",
      "        \"\"\"\n",
      "        LLMの応答をサニタイズするメインメソッド。再帰的なヘルパーを呼び出す。\n",
      "        \"\"\"\n",
      "        return lpml_string \n",
      "        try:\n",
      "            original_tree = parse(lpml_string.strip())\n",
      "            sanitized_tree = self._recursive_sanitize(original_tree)\n",
      "            \n",
      "            # 変更があった場合のみログを出す\n",
      "            # deparseはコストがかかる可能性があるため、必要に応じてlen比較などで代替\n",
      "            final_response = deparse(sanitized_tree)\n",
      "            if lpml_string.strip() != final_response:\n",
      "                 logger.warning(\"Sanitized assistant response by removing/unwrapping tags.\")\n",
      "\n",
      "            return final_response\n",
      "        except Exception as e:\n",
      "            logger.error(f\"Failed to parse/sanitize LLM response: {e}\", exc_info=True)\n",
      "            return lpml_string # エラー時は元の文字列を返す\n",
      "\n",
      "    def _build_full_prompt(self) -> str:\n",
      "        \"\"\"\n",
      "        ベースプロンプトと会話履歴から、LLMに渡す最終的なプロンプト文字列を構築する。\n",
      "        \"\"\"\n",
      "        # ベースプロンプトは常にプロンプトの土台となる\n",
      "        # 会話履歴はLPML要素のリストなので、deparseで文字列に変換\n",
      "        _history = sum(\n",
      "            [[x, '\\n\\n'] for x in self.conversation_history], [])[:-1]\n",
      "        history_str = f\"<log>\\n{deparse(_history)}\\n</log>\"\n",
      "        return f\"{self.prompt}\\n\\n{history_str}\"\n",
      "\n",
      "    async def start(self, initial_task: str, max_turns: int = 10):\n",
      "        \"\"\"対話ループを開始する\"\"\"\n",
      "        if self.state != ContextState.IDLE:\n",
      "            logger.warning(\"Context is already running or finished.\")\n",
      "            return\n",
      "\n",
      "        logger.info(f\"Starting context with initial task: '{initial_task}'\")\n",
      "        self.state = ContextState.RUNNING\n",
      "        \n",
      "        # 最初のタスクを<system>メッセージとして履歴に追加\n",
      "        self.turn_count = 1\n",
      "        self._add_to_history(\"system\", initial_task)\n",
      "\n",
      "        while self.turn_count <= max_turns and self.state == ContextState.RUNNING:\n",
      "            logger.info(f\"--- Turn {self.turn_count}/{max_turns} ---\")\n",
      "\n",
      "            # 1. プロンプトを構築し、LLMに応答を生成させる\n",
      "            prompt_str = self._build_full_prompt()\n",
      "            llm_response_str = await self.llm.generate(prompt_str)\n",
      "            \n",
      "            # 2. LLMの応答をサニタイズ\n",
      "            sanitized_response = self._sanitize_llm_response(llm_response_str)\n",
      "            logger.info(f\"Assistant Response:\\n{sanitized_response}\")\n",
      "            self._add_to_history(\"assistant\", sanitized_response)\n",
      "\n",
      "            # 3. 応答に<wait>タグが含まれているかチェック\n",
      "            if \"<wait>\" in sanitized_response:\n",
      "                logger.info(\"'<wait>' tag found. Context is entering WAITING state.\")\n",
      "                self.state = ContextState.WAITING\n",
      "                break\n",
      "\n",
      "            # 4. Systemにツール実行を依頼\n",
      "            num_tasks = await self.system.process_llm_output(sanitized_response)\n",
      "\n",
      "            # 5. ツールが実行された場合、結果を待って次のターンへ\n",
      "            if num_tasks > 0:\n",
      "                logger.info(\"Waiting for tool results...\")\n",
      "                while True:\n",
      "                    await asyncio.sleep(1)\n",
      "                    tool_results_lpml = await self.system.get_tool_results_as_lpml()\n",
      "                    if tool_results_lpml:\n",
      "                        logger.info(f\"System Response (Tool Results):\\n{tool_results_lpml}\")\n",
      "                        self.turn_count += 1\n",
      "                        self._add_to_history(\"system\", tool_results_lpml)\n",
      "                        break # ポーリングループを抜け、次のLLMターンへ\n",
      "            else:\n",
      "                # ツール実行がなければ、LLMが思考を完了したとみなし待機状態へ\n",
      "                logger.info(\"No tools were executed. Entering WAITING state.\")\n",
      "                self.state = ContextState.WAITING\n",
      "                break\n",
      "        \n",
      "        if self.state == ContextState.RUNNING:\n",
      "            logger.warning(f\"Max turns ({max_turns}) reached. Setting state to TERMINATED.\")\n",
      "            self.state = ContextState.TERMINATED\n",
      "\n",
      "        logger.info(f\"--- Context loop finished with state: {self.state.name} ---\")</output>\n",
      "</system>\n",
      "\n",
      "<assistant turn=\"3\" timestamp=\"2025-09-01T22:34:50.229376+00:00\">\n",
      "<assistant turn=\"3\" timestamp=\"2025-09-01T22:34:44.445648+00:00\">\n",
      "<thinking label=\"Analyze context.py\">\n",
      "The `context.py` file defines the `Context` class, which is central to the `solipsism` project.\n",
      "It manages the conversation history, context state (`IDLE`, `RUNNING`, `WAITING`, `TERMINATED`), and orchestrates the dialogue loop between the LLM and the System.\n",
      "\n",
      "Key components and their roles:\n",
      "-   `ConversationHistory`: A list of `Element` objects, representing the dialogue.\n",
      "-   `ContextState`: Enum to track the context's operational status.\n",
      "-   `__init__`: Initializes the context with an LLM, a System, and loads a `base_prompt`.\n",
      "-   `prompt` property: Combines the `base_prompt` and `system.get_tool_definitions()`. This is crucial as it indicates that the system provides tool definitions to the LLM.\n",
      "-   `_add_to_history`: Adds new dialogue elements (system or assistant messages) to `conversation_history` with turn and timestamp attributes.\n",
      "-   `_recursive_sanitize` and `_sanitize_llm_response`: These methods are intended to clean up LLM responses. Notably, `<system>` tags are removed, and `<assistant>` tags are unwrapped (their content replaces the tag itself). However, the `_sanitize_llm_response` method currently returns the original `lpml_string` directly, indicating that sanitization is effectively disabled (`return lpml_string`). This is a point of interest for potential future modification or current debugging.\n",
      "-   `_build_full_prompt`: Constructs the complete prompt for the LLM by combining the `base_prompt`, tool definitions, and the `conversation_history` wrapped in a `<log>` tag. This confirms that the entire dialogue history is provided to the LLM.\n",
      "-   `start` method: This is the core dialogue loop.\n",
      "    -   It initializes the `turn_count` and adds the `initial_task` as a `<system>` message.\n",
      "    -   It enters a `while` loop, continuing as long as `turn_count` is within `max_turns` and the state is `RUNNING`.\n",
      "    -   Inside the loop:\n",
      "        1.  It builds the prompt and calls `self.llm.generate()` to get an LLM response.\n",
      "        2.  It calls `_sanitize_llm_response` (which is currently a no-op).\n",
      "        3.  It adds the LLM's response as an `<assistant>` message to history.\n",
      "        4.  **Crucially, it checks for a `<wait>` tag in the LLM's response.** If found, the context enters `WAITING` state and breaks the loop. This aligns with the `wait` tag definition.\n",
      "        5.  It calls `self.system.process_llm_output()` with the LLM's response. This implies the `System` class is responsible for parsing and executing tags from the LLM.\n",
      "        6.  If tools were executed (`num_tasks > 0`), it enters another `while` loop to `asyncio.sleep(1)` and `self.system.get_tool_results_as_lpml()` to poll for results. Once results are available, they are added as a `<system>` message to history, and the loop continues to the next LLM turn. This confirms the asynchronous nature and the polling mechanism described in the `context` rule.\n",
      "        7.  If no tools were executed, the context enters `WAITING` state, implying the LLM has completed its immediate task or is waiting for external input.\n",
      "    -   The loop also handles `max_turns` and sets the state to `TERMINATED` if reached.\n",
      "\n",
      "From this, I understand that:\n",
      "-   The `Context` class is the orchestrator.\n",
      "-   It uses an `LLM` to generate responses and a `System` to execute actions based on those responses.\n",
      "-   The `conversation_history` is critical for maintaining context.\n",
      "-   The `<wait>` tag is a mechanism for the LLM (me) to explicitly pause execution.\n",
      "-   The system asynchronously executes tools and reports results back to the context.\n",
      "-   The `_sanitize_llm_response` function is currently not active, meaning LLM outputs are processed as-is by the system.\n",
      "</thinking>\n",
      "<reflection target=\"Analyze context.py\" label=\"Reflect on context.py analysis\">\n",
      "The analysis confirms the core loop described in the `context` rule. The interaction between `LLM`, `System`, and `Context` is clear. The `_sanitize_llm_response` being a no-op is an important detail; it means I need to be careful with my output format as the system will directly parse it. The polling mechanism for tool results is also well-defined. The `wait` tag's function is critical for managing the context's lifecycle and aligns with my understanding of when to use it.\n",
      "</reflection>\n",
      "<thinking label=\"Plan next file read\">\n",
      "I have a good understanding of `context.py`. The `readme.md` also suggested reading `system.py` and `llm.py`. Given that `context.py` heavily interacts with `system.py` for tool execution and `llm.py` for response generation, it makes sense to read `system.py` next to understand how tools are processed.\n",
      "</thinking>\n",
      "<read_file path=\"./solipsism/core/system.py\"/>\n",
      "</assistant>\n",
      "</assistant>\n",
      "</log>\n"
     ]
    }
   ],
   "source": [
    "print(context._build_full_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1161932c-8529-4ad2-b789-eb04d1980438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ContextState.WAITING: 3>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87dee363-f662-4eef-8a82-5874304618b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<define_tag name=\"read_file\">\n",
      "Reads the content of a specified file.\n",
      "Attributes:\n",
      "    - path (required): The path to the file.\n",
      "    - line_numbers (optional): If \"true\", prepends line numbers to the output.\n",
      "</define_tag>\n",
      "\n",
      "<define_tag name=\"write_file\">\n",
      "Writes or modifies a file. The content is placed inside the tag.\n",
      "Attributes:\n",
      "    - path (required): The path to the file.\n",
      "    - mode (optional): \"overwrite\", \"append\", \"replace_lines\", \"insert_at_line\". Default: \"overwrite\".\n",
      "    - start_line, end_line (for replace_lines): The 1-indexed line range to replace.\n",
      "    - line (for insert_at_line): The 1-indexed line number to insert at.\n",
      "</define_tag>\n"
     ]
    }
   ],
   "source": [
    "print(system.get_tool_definitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "136b87fc-a943-492a-9f6e-a7d27cff43a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    <define_tag name=\"list_files\">\n",
      "    test\n",
      "    </define_tag>\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(file_io.ListFilesTool.tag_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b41f3f5f-e866-409c-a491-5ae31dfc512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GeminiLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af9cc79f-b7e9-41ef-aa87-a963eaaaac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = llm.upload_file(\"../solipsism/core/lpml.py\")\n",
    "a = await llm.generate(f\"../solipsism/core/lpml.pyについて説明して\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4b4d072-627d-48e1-b26e-f13d5334533d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`../solipsism/core/lpml.py` ファイルは、LPML (Lightweight Python Markup Language) と呼ばれるシンプルなマークアップ言語を解析、逆解析、および操作するためのユーティリティを提供します。LPML は、HTML や XML に似ていますが、Python で簡単に処理できるように設計されています。\n",
      "\n",
      "以下に、ファイルの各部分の詳細な説明を示します。\n",
      "\n",
      "### インポート\n",
      "\n",
      "```python\n",
      "import re\n",
      "from typing import List, Dict, Union, Optional\n",
      "```\n",
      "\n",
      "- `re`: 正規表現を操作するためのPythonの標準モジュールです。LPMLタグのパターンマッチングに使用されます。\n",
      "- `typing`: 型ヒントを提供するためのモジュールです。コードの可読性と保守性を向上させます。\n",
      "\n",
      "### 型定義\n",
      "\n",
      "```python\n",
      "Attributes = Dict[str, str]\n",
      "Element = Dict[str, Union[str, Attributes, List['Element']]]\n",
      "LPMLTree = List[Union[str, Element]]\n",
      "```\n",
      "\n",
      "- `Attributes`: キーが文字列で値も文字列である辞書型を表します。これはLPML要素の属性を格納するために使用されます。例: `{'id': 'my-id', 'class': 'my-class'}`。\n",
      "- `Element`: LPML要素を表す辞書型です。\n",
      "    - `'tag'`: 要素のタグ名 (文字列)。\n",
      "    - `'attributes'`: 要素の属性 (Attributes型)。\n",
      "    - `'content'`: 要素の内容。これは以下のいずれかになります。\n",
      "        - `str`: 単一の文字列コンテンツ。\n",
      "        - `List['Element']`: 子要素のリスト。\n",
      "        - `None`: 空タグの場合 (例: `<br/>`)。\n",
      "- `LPMLTree`: LPMLドキュメント全体を表すリスト型です。このリストには、文字列 (テキストコンテンツ) または `Element` オブジェクトが含まれます。\n",
      "\n",
      "### 正規表現パターン\n",
      "\n",
      "```python\n",
      "PATTERN_ATTRIBUTE = r''' ([^\"'/<> -]+)=(?:\"([^\"]*)\"|'([^']*)')'''\n",
      "PATTERN_ATTRIBUTE_NO_CAPTURE = r''' [^\"'/<> -]+=(?:\"[^\"]*\"|'[^']*')'''\n",
      "PATTERN_TAG_START = rf'<([^/>\\s\\n]+)((?:{PATTERN_ATTRIBUTE_NO_CAPTURE})*)\\s*>'\n",
      "PATTERN_TAG_END = r'</([^/>\\s\\n]+)\\s*>'\n",
      "PATTERN_TAG_EMPTY = rf'<([^/>\\s\\n]+)((?:{PATTERN_ATTRIBUTE_NO_CAPTURE})*)\\s*/>'\n",
      "PATTERN_TAG = rf'({PATTERN_TAG_START}|{PATTERN_TAG_END}|{PATTERN_TAG_EMPTY})'\n",
      "```\n",
      "\n",
      "LPMLタグを識別するための正規表現パターンが定義されています。\n",
      "\n",
      "- `PATTERN_ATTRIBUTE`: 属性をキャプチャするためのパターン。`key=\"value\"` または `key='value'` の形式に一致します。\n",
      "    - `([^\"'/<> -]+)`: 属性キー (グループ1)。\n",
      "    - `(?:\"([^\"]*)\"|'([^']*)')`: 属性値 (グループ2または3)。\n",
      "- `PATTERN_ATTRIBUTE_NO_CAPTURE`: 属性をキャプチャしないバージョン。主に他のパターン内で属性の存在をチェックするために使用されます。\n",
      "- `PATTERN_TAG_START`: 開始タグ (例: `<tag attr=\"val\">`) に一致するパターン。\n",
      "    - `([^/>\\s\\n]+)`: タグ名 (グループ1)。\n",
      "    - `((?:{PATTERN_ATTRIBUTE_NO_CAPTURE})*)`: 0個以上の属性 (グループ2)。\n",
      "- `PATTERN_TAG_END`: 終了タグ (例: `</tag>`) に一致するパターン。\n",
      "    - `([^/>\\s\\n]+)`: タグ名 (グループ1)。\n",
      "- `PATTERN_TAG_EMPTY`: 空タグ (例: `<tag attr=\"val\"/>`) に一致するパターン。\n",
      "    - `([^/>\\s\\n]+)`: タグ名 (グループ1)。\n",
      "    - `((?:{PATTERN_ATTRIBUTE_NO_CAPTURE})*)`: 0個以上の属性 (グループ2)。\n",
      "- `PATTERN_TAG`: 開始タグ、終了タグ、空タグのいずれかに一致する複合パターン。これは `re.finditer` でLPMLテキスト内のすべてのタグを見つけるために使用されます。\n",
      "\n",
      "### 内部ヘルパー関数\n",
      "\n",
      "#### `_parse_attributes(text: str) -> Attributes`\n",
      "\n",
      "- **目的**: 属性文字列から辞書形式の属性を解析します。\n",
      "- **引数**:\n",
      "    - `text` (str): 属性を含む文字列 (例: `' id=\"my-id\" class=\"my-class\"'`)。\n",
      "- **戻り値**: `Attributes` (辞書)。\n",
      "- **詳細**: `PATTERN_ATTRIBUTE` を使用して、指定されたテキストからすべての属性キーと値を抽出し、それらを辞書として返します。\n",
      "\n",
      "### 公開関数\n",
      "\n",
      "#### `parse(text: str, strip: bool = False, exclude: Optional[List[str]] = None) -> LPMLTree`\n",
      "\n",
      "- **目的**: LPMLテキストを解析し、LPMLツリー構造に変換します。\n",
      "- **引数**:\n",
      "    - `text` (str): 解析するLPMLテキスト。\n",
      "    - `strip` (bool, オプション, デフォルトは `False`): タグ間のテキストコンテンツから空白を削除するかどうか。\n",
      "    - `exclude` (List[str], オプション, デフォルトは `None`): 指定されたタグ内のコンテンツは解析されません。これらのタグは単一の文字列として扱われます。\n",
      "- **戻り値**: `LPMLTree` (解析されたツリー)。\n",
      "- **詳細**:\n",
      "    1. `exclude` リストを初期化します。\n",
      "    2. `tree` (最終的な解析結果) と `stack` (タグのネストを追跡するためのスタック) を初期化します。\n",
      "    3. `re.finditer(PATTERN_TAG, text)` を使用して、テキスト内のすべてのLPMLタグを順次見つけます。\n",
      "    4. 各タグについて、以下の処理を行います。\n",
      "        - タグの前のテキストコンテンツを抽出し、現在のスタックの最上位のコンテンツに追加します。\n",
      "        - タグの種類 (開始、終了、空) を判別します。\n",
      "        - **開始タグ**の場合:\n",
      "            - タグ名と属性を解析します。\n",
      "            - 新しい `Element` を作成し、現在のスタックの最上位のコンテンツに追加します。\n",
      "            - 新しい `Element` をスタックにプッシュします (ネストのため)。\n",
      "            - `exclude` リストにタグ名が含まれている場合、`tag_exclude` を設定してそのタグのコンテンツの解析をスキップします。\n",
      "        - **空タグ**の場合:\n",
      "            - タグ名と属性を解析します。\n",
      "            - 新しい `Element` を作成し、現在のスタックの最上位のコンテンツに追加します。コンテンツは `None` に設定されます。\n",
      "        - **終了タグ**の場合:\n",
      "            - スタックを遡って、対応する開始タグを見つけます。\n",
      "            - 見つかった場合、その開始タグまでスタックをポップします。\n",
      "            - 見つからない場合、「Unmatched closing tag」の警告を出力します。\n",
      "    5. すべてのタグの処理が終わった後、残りのテキストコンテンツを処理します。\n",
      "    6. スタックに未クローズの要素が残っている場合、「Unclosed elements remain」の警告を出力します。\n",
      "    7. 最終的な `tree` を返します。\n",
      "\n",
      "#### `deparse(tree: LPMLTree) -> str`\n",
      "\n",
      "- **目的**: LPMLツリー構造を元のLPMLテキストに逆解析します。\n",
      "- **引数**:\n",
      "    - `tree` (LPMLTree): 逆解析するツリー。\n",
      "- **戻り値**: `str` (逆解析されたテキスト)。\n",
      "- **詳細**:\n",
      "    1. ツリーが `None` の場合は `None` を返します。\n",
      "    2. ツリー内の各要素を反復処理します。\n",
      "    3. 要素が文字列の場合、そのまま結果に追加します。\n",
      "    4. 要素が `Element` の場合:\n",
      "        - 再帰的に `element['content']` を `deparse` して子コンテンツを取得します。\n",
      "        - `_repr_tag` ヘルパー関数を使用して、タグ、コンテンツ、属性から適切なLPML文字列を生成し、結果に追加します。\n",
      "\n",
      "#### `_repr_tag(tag, content, **kwargs)` (内部ヘルパー関数)\n",
      "\n",
      "- **目的**: タグ名、コンテンツ、属性からLPMLタグの文字列表現を生成します。\n",
      "- **引数**:\n",
      "    - `tag` (str): タグ名。\n",
      "    - `content` (strまたはNone): タグのコンテンツ。\n",
      "    - `**kwargs`: 属性のキーと値のペア。\n",
      "- **戻り値**: `str`。\n",
      "- **詳細**:\n",
      "    - 属性がある場合、`key=\"value\"` 形式の文字列を作成します。\n",
      "    - `content` が `None` の場合、空タグ (例: `<tag/>`) を返します。\n",
      "    - それ以外の場合、開始タグ、コンテンツ、終了タグを連結して返します。\n",
      "\n",
      "#### `findall(tree: LPMLTree, tag: str) -> List[Element]`\n",
      "\n",
      "- **目的**: 指定されたタグ名を持つすべての要素をLPMLツリーから検索します。\n",
      "- **引数**:\n",
      "    - `tree` (LPMLTree): 検索するツリー。\n",
      "    - `tag` (str): 検索するタグ名。\n",
      "- **戻り値**: `List[Element]` (見つかった要素のリスト)。\n",
      "- **詳細**:\n",
      "    1. ツリーが `None` の場合は空リストを返します。\n",
      "    2. ツリー内の各要素を反復処理します。\n",
      "    3. 要素が辞書 (つまり `Element`) であり、そのタグが指定されたタグと一致する場合、結果リストに追加します。\n",
      "    4. 要素が `Element` であれば、その `content` に対して再帰的に `findall` を呼び出し、結果を結合します。\n",
      "\n",
      "#### `generate_element(tag: str, content: str, **attributes) -> Element`\n",
      "\n",
      "- **目的**: 新しいLPML要素を簡単に作成するためのヘルパー関数。\n",
      "- **引数**:\n",
      "    - `tag` (str): タグ名。\n",
      "    - `content` (str): 要素のコンテンツ。\n",
      "    - `**attributes`: 属性のキーと値のペア。\n",
      "- **戻り値**: `Element` (作成された要素)。\n",
      "- **詳細**: 指定された引数を使用して `Element` 辞書を構築し、返します。\n",
      "\n",
      "### まとめ\n",
      "\n",
      "`lpml.py` は、LPMLというシンプルなマークアップ言語をPythonで扱うための包括的なツールセットを提供します。正規表現を使ってテキストを解析し、Pythonの辞書とリストで構成されるツリー構造に変換します。また、その逆の変換（逆解析）、特定のタグの検索、新しい要素の生成といった機能も備えています。これにより、LPML形式のデータをプログラムで簡単に生成、操作、読み込みすることが可能になります。\n"
     ]
    }
   ],
   "source": [
    "print(a.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a67d704-b44c-4e26-9f83-76881785a2c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mfile\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'file' is not defined"
     ]
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff64e344-e73a-4eab-be3f-aaeb91ca7674",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = await llm.generate(\"こんにちは!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0d925c5-2cd8-4d2d-9885-94cbc9e43629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`files/solipsism-core-lpml-py` は、LPML (Lightweight Python Markup Language) と呼ばれるマークアップ言語を解析 (parse) し、逆解析 (deparse) するためのPythonモジュールです。XML/HTMLに似た構造を持つテキストデータを、Pythonのデータ構造（辞書とリストのネスト）に変換したり、その逆を行ったりする機能を提供します。\n",
      "\n",
      "以下に、このモジュールの主要な部分と機能について詳しく説明します。\n",
      "\n",
      "---\n",
      "\n",
      "### 1. LPMLのデータ構造の定義\n",
      "\n",
      "このモジュールでは、LPMLのツリー構造を表現するために以下の型エイリアスが定義されています。\n",
      "\n",
      "```python\n",
      "Attributes = Dict[str, str]\n",
      "Element = Dict[str, Union[str, Attributes, List['Element']]]\n",
      "LPMLTree = List[Union[str, Element]]\n",
      "```\n",
      "\n",
      "- **`Attributes`**: タグの属性を表現する辞書。キーと値はどちらも文字列です (例: `{'id': 'my-div', 'class': 'container'}`)。\n",
      "- **`Element`**: LPMLの要素（タグ）を表現する辞書。\n",
      "    - `'tag'`: タグ名 (文字列)。\n",
      "    - `'attributes'`: `Attributes` 型の辞書。\n",
      "    - `'content'`: 要素の内容。これは以下のいずれかになります。\n",
      "        - `None`: 空のタグ (例: `<br/>`)。\n",
      "        - `str`: テキストコンテンツ。\n",
      "        - `List['Element']`: ネストされたLPMLツリー。\n",
      "- **`LPMLTree`**: LPMLドキュメント全体、または要素のコンテンツを表現するリスト。このリストには、テキストコンテンツ (文字列) または`Element`オブジェクトが含まれます。\n",
      "\n",
      "---\n",
      "\n",
      "### 2. 正規表現パターン\n",
      "\n",
      "LPMLのタグを識別するために、いくつかの正規表現パターンが定義されています。\n",
      "\n",
      "- **`PATTERN_ATTRIBUTE`**: 属性のキーと値をキャプチャするためのパターン。\n",
      "- **`PATTERN_ATTRIBUTE_NO_CAPTURE`**: 属性をキャプチャせずにマッチさせるためのパターン（主に他のパターンの内部で使用）。\n",
      "- **`PATTERN_TAG_START`**: 開始タグ (例: `<div id=\"foo\">`) を検出するためのパターン。\n",
      "- **`PATTERN_TAG_END`**: 終了タグ (例: `</div>`) を検出するためのパターン。\n",
      "- **`PATTERN_TAG_EMPTY`**: 空タグ (例: `<img src=\"bar\"/>`) を検出するためのパターン。\n",
      "- **`PATTERN_TAG`**: 上記3つのタグパターンをまとめて検出するためのパターン。\n",
      "\n",
      "---\n",
      "\n",
      "### 3. `_parse_attributes(text: str) -> Attributes`\n",
      "\n",
      "与えられた属性文字列から属性の辞書を解析するヘルパー関数です。\n",
      "例えば、`'id=\"my-id\" class=\"my-class\"'` という文字列から `{'id': 'my-id', 'class': 'my-class'}` を生成します。\n",
      "\n",
      "---\n",
      "\n",
      "### 4. `parse(text: str, strip: bool = False, exclude: Optional[List[str]] = None) -> LPMLTree`\n",
      "\n",
      "LPMLテキストを解析し、Pythonのデータ構造（`LPMLTree`）に変換する主要な関数です。\n",
      "\n",
      "**引数:**\n",
      "- `text` (str): 解析するLPMLテキスト。\n",
      "- `strip` (bool, オプション): `True` の場合、タグ間のテキストコンテンツの先頭と末尾の空白文字を削除します。デフォルトは `False`。\n",
      "- `exclude` (List[str], オプション): 指定されたタグ名を持つ要素のコンテンツは解析されません（そのまま文字列として扱われます）。例えば、`<script>` タグの内容をそのまま保持したい場合などに便利です。\n",
      "\n",
      "**処理の概要:**\n",
      "1. `LPMLTree` 型の空のリスト `tree` を初期化します。\n",
      "2. スタックベースの解析アプローチを使用します。`stack` は、現在処理中の要素の階層を追跡します。\n",
      "3. `re.finditer(PATTERN_TAG, text)` を使用して、テキスト内のすべてのLPMLタグを順に検索します。\n",
      "4. 各タグについて、以下のいずれかのケースを処理します。\n",
      "    - **開始タグ (`<tag ...>`):**\n",
      "        - タグ名と属性を抽出し、新しい `Element` オブジェクトを作成します。\n",
      "        - `exclude` リストにタグ名が含まれている場合、そのタグのコンテンツは解析をスキップします (`tag_exclude` を設定)。\n",
      "        - 現在の親要素の `content` リストにこの `Element` を追加します。\n",
      "        - この `Element` をスタックにプッシュし、次の要素の親とします。\n",
      "    - **空タグ (`<tag .../>`):**\n",
      "        - タグ名と属性を抽出し、`content` が `None` の `Element` オブジェクトを作成します。\n",
      "        - 現在の親要素の `content` リストにこの `Element` を追加します。\n",
      "    - **終了タグ (`</tag>`):**\n",
      "        - 対応する開始タグを見つけるためにスタックを遡ります。\n",
      "        - スタックから対応する要素をポップします。\n",
      "        - 対応する開始タグが見つからない場合は警告を出力します。\n",
      "5. タグとタグの間、および最初と最後のタグの外側にあるテキストは、現在の親要素の `content` リストに文字列として追加されます。\n",
      "6. 解析終了後、閉じられていない要素がスタックに残っている場合は警告を出力します。\n",
      "\n",
      "**返り値:**\n",
      "- `LPMLTree`: 解析されたLPMLツリー。\n",
      "\n",
      "---\n",
      "\n",
      "### 5. `_repr_tag(tag, content, **kwargs)`\n",
      "\n",
      "`deparse` 関数内で使用されるヘルパー関数で、タグ、コンテンツ、属性からLPMLの文字列表現を生成します。\n",
      "\n",
      "---\n",
      "\n",
      "### 6. `deparse(tree: LPMLTree) -> str`\n",
      "\n",
      "LPMLツリーをLPMLテキストに逆解析（変換）する関数です。\n",
      "\n",
      "**引数:**\n",
      "- `tree` (LPMLTree): 逆解析するLPMLツリー。\n",
      "\n",
      "**処理の概要:**\n",
      "1. `text` を空文字列で初期化します。\n",
      "2. ツリー内の各要素を順に処理します。\n",
      "3. 要素が文字列（テキストコンテンツ）の場合、そのまま `text` に追加します。\n",
      "4. 要素が辞書（`Element`）の場合、再帰的に `element['content']` を `deparse` し、`_repr_tag` を使用してタグの文字列表現を生成し、`text` に追加します。\n",
      "\n",
      "**返り値:**\n",
      "- `str`: 逆解析されたLPMLテキスト。\n",
      "\n",
      "---\n",
      "\n",
      "### 7. `findall(tree: LPMLTree, tag: str) -> List[Element]`\n",
      "\n",
      "LPMLツリー内で指定されたタグ名を持つすべての要素を検索する関数です。\n",
      "\n",
      "**引数:**\n",
      "- `tree` (LPMLTree): 検索対象のLPMLツリー。\n",
      "- `tag` (str): 検索するタグ名。\n",
      "\n",
      "**処理の概要:**\n",
      "1. `result` リストを初期化します。\n",
      "2. ツリー内の各要素を順に処理します。\n",
      "3. 要素が辞書であり、その `tag` が指定された `tag` と一致する場合、その要素を `result` に追加します。\n",
      "4. 要素の `content` が存在し、それがリストである場合、再帰的に `findall` を呼び出してネストされた要素も検索し、結果を `result` に追加します。\n",
      "\n",
      "**返り値:**\n",
      "- `List[Element]`: 指定されたタグ名を持つすべての要素のリスト。\n",
      "\n",
      "---\n",
      "\n",
      "### 8. `generate_element(tag: str, content: str, **attributes) -> Element`\n",
      "\n",
      "新しい `Element` オブジェクトを簡単に生成するためのヘルパー関数です。\n",
      "\n",
      "**引数:**\n",
      "- `tag` (str): タグ名。\n",
      "- `content` (str): コンテンツ。\n",
      "- `**attributes`: キーワード引数として渡された属性。\n",
      "\n",
      "**返り値:**\n",
      "- `Element`: 生成された要素辞書。\n",
      "\n",
      "---\n",
      "\n",
      "### 全体的な目的\n",
      "\n",
      "この `lpml.py` モジュールは、カスタムのマークアップ言語であるLPMLを扱うための基本的なツールキットを提供します。これにより、LPML形式のテキストデータをPythonプログラムで簡単に操作し、Pythonのデータ構造とLPMLテキストの間で相互変換を行うことができます。これは、例えば、設定ファイル、テンプレートエンジン、あるいは独自のデータ記述形式を実装する際に役立つでしょう。\n"
     ]
    }
   ],
   "source": [
    "print(a.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a2133f5-b72e-4fbd-94a2-415a49359966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system = System()\n",
    "system.add_tool(file_io.ListFilesTool(root_path=\"./\"))\n",
    "await system.process_llm_output('<list_files path=\"./\"></list_files><list_files path=\"./\"><a><</list_files>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08d88548-5960-4dc2-a995-c7b742ee3cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = await system.get_tool_results_as_lpml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bf7cb10-5f1b-44f9-b08c-ab52282ed008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<output tool=\"list_files\" path=\"./\">\n",
      "Untitled.ipynb\n",
      ".ipynb_checkpoints\n",
      "</output>\n",
      "\n",
      "<output tool=\"list_files\" path=\"./\">\n",
      "Untitled.ipynb\n",
      ".ipynb_checkpoints\n",
      "</output>\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8491e04b-e58e-4606-a512-2757d4b0cd11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list({\"a\":1}.keys()) + [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99994b81-7a86-467c-a1eb-1afbf90fbc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, ',', 2, ',', 3]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = [1, 2, 3]\n",
    "result = [item for sublist in [[x, ','] for x in my_list] for item in sublist][:-1]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83cd9046-36f6-4830-ac4e-abe11a614791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, ',', 2, ',', 3, ',']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([[x, ','] for x in my_list], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88595e5f-54a8-45a3-9ded-1934b3321c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<hoge/>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lpml.deparse(lpml.parse(\"<hoge  />\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2541a0c0-49f5-4a6a-8fbb-f8968e30b9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "\n",
    "# プロデューサーのコルーチン\n",
    "async def producer(queue: asyncio.Queue, num_items: int):\n",
    "    \"\"\"\n",
    "    指定された数のアイテムを生成し、キューに追加します。\n",
    "    \"\"\"\n",
    "    for i in range(num_items):\n",
    "        item = f\"item-{i}\"\n",
    "        await asyncio.sleep(random.uniform(0.1, 0.5))  # データ生成のシミュレーション\n",
    "        await queue.put(item)\n",
    "        print(f\"Producer put: {item}\")\n",
    "    await queue.put(None)  # 終了シグナルとしてNoneを追加\n",
    "\n",
    "# コンシューマーのコルーチン\n",
    "async def consumer(queue: asyncio.Queue):\n",
    "    \"\"\"\n",
    "    キューからアイテムを取得し、処理します。\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        item = await queue.get()\n",
    "        if item is None:\n",
    "            await queue.put(None)  # 他のコンシューマーに終了シグナルを転送\n",
    "            break\n",
    "        print(f\"Consumer got: {item}\")\n",
    "        await asyncio.sleep(random.uniform(0.1, 0.5))  # データ処理のシミュレーション\n",
    "\n",
    "# メインのコルーチン\n",
    "async def main():\n",
    "    queue = asyncio.Queue()\n",
    "    num_items_to_produce = 5\n",
    "\n",
    "    # プロデューサーとコンシューマーのタスクを同時に実行\n",
    "    producer_task = asyncio.create_task(producer(queue, num_items_to_produce))\n",
    "    consumer_task = asyncio.create_task(consumer(queue))\n",
    "\n",
    "    # 両方のタスクが完了するのを待つ\n",
    "    await asyncio.gather(producer_task, consumer_task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3deeb863-c69a-4e49-8a9c-497d212a0554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producer put: item-0\n",
      "Consumer got: item-0\n",
      "Producer put: item-1\n",
      "Consumer got: item-1\n",
      "Producer put: item-2\n",
      "Consumer got: item-2\n",
      "Producer put: item-3\n",
      "Consumer got: item-3\n",
      "Producer put: item-4\n",
      "Consumer got: item-4\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60e8af43-ad4d-4a55-bbee-a0f44012bc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121514/100004491.py:4: RuntimeWarning: coroutine 'ListFilesTool.run' was never awaited\n",
      "  file_io.ListFilesTool().run({\"tag\": \"hoge\", \"attributes\": {\"path\": \"./\"}}, queue)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "An asyncio.Future, a coroutine or an awaitable is required",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m queue = asyncio.Queue()\n\u001b[32m      4\u001b[39m file_io.ListFilesTool().run({\u001b[33m\"\u001b[39m\u001b[33mtag\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mhoge\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mattributes\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m./\u001b[39m\u001b[33m\"\u001b[39m}}, queue)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.6-linux-x86_64-gnu/lib/python3.13/asyncio/tasks.py:884\u001b[39m, in \u001b[36mgather\u001b[39m\u001b[34m(return_exceptions, *coros_or_futures)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m coros_or_futures:\n\u001b[32m    883\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m arg \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m arg_to_fut:\n\u001b[32m--> \u001b[39m\u001b[32m884\u001b[39m         fut = \u001b[43mensure_future\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    885\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m loop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    886\u001b[39m             loop = futures._get_loop(fut)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.6-linux-x86_64-gnu/lib/python3.13/asyncio/tasks.py:742\u001b[39m, in \u001b[36mensure_future\u001b[39m\u001b[34m(coro_or_future, loop)\u001b[39m\n\u001b[32m    740\u001b[39m         should_close = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    741\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m742\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mAn asyncio.Future, a coroutine or an awaitable \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    743\u001b[39m                         \u001b[33m'\u001b[39m\u001b[33mis required\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    746\u001b[39m     loop = events.get_event_loop()\n",
      "\u001b[31mTypeError\u001b[39m: An asyncio.Future, a coroutine or an awaitable is required"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "queue = asyncio.Queue()\n",
    "file_io.ListFilesTool().run({\"tag\": \"hoge\", \"attributes\": {\"path\": \"./\"}}, queue)\n",
    "await asyncio.gather(queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa62c21-9e06-43c8-8df8-96b538bd797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Element("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c36575ab-c9cc-495a-9d7f-aba182dd1e67",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Type Dict cannot be instantiated; use dict() instead",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mlpml\u001b[49m\u001b[43m.\u001b[49m\u001b[43mElement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtag\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.6-linux-x86_64-gnu/lib/python3.13/typing.py:1315\u001b[39m, in \u001b[36m_BaseGenericAlias.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1313\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m   1314\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inst:\n\u001b[32m-> \u001b[39m\u001b[32m1315\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mType \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cannot be instantiated; \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1316\u001b[39m                         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33muse \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.__origin__.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() instead\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1317\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.__origin__(*args, **kwargs)\n\u001b[32m   1318\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mTypeError\u001b[39m: Type Dict cannot be instantiated; use dict() instead"
     ]
    }
   ],
   "source": [
    "lpml.Element(tag=\"tag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9297f1-0dbb-4e05-918a-0a62417db02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def func():\n",
    "    asyncio.sleep(3)\n",
    "    return None\n",
    "\n",
    "async for i in range(5):\n",
    "    queue.put"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solipsism",
   "language": "python",
   "name": "solipsism"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
